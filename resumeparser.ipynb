{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume parser using NLP\n",
    "\n",
    "### Niam Bashambu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import pdfplumber\n",
    "import docx\n",
    "import spacy\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text extraction functions\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs]).strip()\n",
    "\n",
    "def extract_text(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        return extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_contact_info(text):\n",
    "    email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "    phone_pattern = r\"\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\"\n",
    "\n",
    "    email = re.findall(email_pattern, text)\n",
    "    phone = re.findall(phone_pattern, text)\n",
    "\n",
    "    return email[0] if email else None, phone[0] if phone else None\n",
    "\n",
    "def extract_name(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return ent.text\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_education(text):\n",
    "    doc = nlp(text)\n",
    "    education = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"ORG\"]:  # Universities often tagged as ORG\n",
    "            education.append(ent.text)\n",
    "    return list(set(education))  # Remove duplicates\n",
    "\n",
    "def extract_experience(text):\n",
    "    doc = nlp(text)\n",
    "    experience = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"ORG\", \"GPE\"]:  # Companies and locations often tagged as ORG/GPE\n",
    "            experience.append(ent.text)\n",
    "    return list(set(experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(text):\n",
    "    doc = nlp(text)\n",
    "    skills = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"PRODUCT\", \"WORK_OF_ART\"]:  # Often used for tools, tech names\n",
    "            skills.append(ent.text)\n",
    "    \n",
    "    # Add general nouns (common for skills)\n",
    "    skills.extend([token.text for token in doc if token.pos_ == \"NOUN\" and len(token.text) > 1])\n",
    "\n",
    "    return list(set(skills))  # Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_resume(file_path):\n",
    "    text = extract_text(file_path)\n",
    "    if not text:\n",
    "        return {\"error\": \"Unsupported file format\"}\n",
    "\n",
    "    name = extract_name(text)\n",
    "    email, phone = extract_contact_info(text)\n",
    "    education = extract_education(text)\n",
    "    experience = extract_experience(text)\n",
    "    skills = extract_skills(text)\n",
    "\n",
    "    parsed_resume = {\n",
    "        \"Name\": name,\n",
    "        \"Email\": email,\n",
    "        \"Phone\": phone,\n",
    "        \"Education\": education,\n",
    "        \"Experience\": experience,\n",
    "        \"Skills\": skills\n",
    "    }\n",
    "\n",
    "    return parsed_resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Niam Bashambu',\n",
       " 'Email': 'niambashambu@icloud.com',\n",
       " 'Phone': '415-999-9281',\n",
       " 'Education': ['• Collaborated',\n",
       "  '• Conducted',\n",
       "  'CSS',\n",
       "  'StudyPlanGPT',\n",
       "  'AI',\n",
       "  'Saint Louis University',\n",
       "  '• Implemented',\n",
       "  'Khoury College of Computer Sciences',\n",
       "  '• Trained',\n",
       "  'NJ Jul',\n",
       "  'Bay Takes',\n",
       "  'OptiRun',\n",
       "  'SQL',\n",
       "  'API',\n",
       "  'Business Statistics',\n",
       "  'HTML',\n",
       "  'Bachelor of Sciences: Data Science and Business Administration GPA',\n",
       "  '• Contributed',\n",
       "  'Northeastern University',\n",
       "  'Financial Accounting',\n",
       "  'Algorithms and Data, Discrete Structures',\n",
       "  'Advanced Programming with Data',\n",
       "  'Project Intern\\n• Worked',\n",
       "  'MA Sep',\n",
       "  'Strava',\n",
       "  'TikTok'],\n",
       " 'Experience': ['• Collaborated',\n",
       "  '• Conducted',\n",
       "  'Node.js',\n",
       "  'Boston',\n",
       "  'Oakland',\n",
       "  'CSS',\n",
       "  'StudyPlanGPT',\n",
       "  'Madrid',\n",
       "  'AI',\n",
       "  'Saint Louis University',\n",
       "  '• Implemented',\n",
       "  'Khoury College of Computer Sciences',\n",
       "  '• Trained',\n",
       "  'NJ Jul',\n",
       "  'Bay Takes',\n",
       "  'OptiRun',\n",
       "  'Keras',\n",
       "  'SQL',\n",
       "  'Flask',\n",
       "  'Camden',\n",
       "  'API',\n",
       "  'Business Statistics',\n",
       "  'HTML',\n",
       "  'NumPy',\n",
       "  'Bachelor of Sciences: Data Science and Business Administration GPA',\n",
       "  '• Contributed',\n",
       "  'Northeastern University',\n",
       "  'Financial Accounting',\n",
       "  'Algorithms and Data, Discrete Structures',\n",
       "  'Django',\n",
       "  'Advanced Programming with Data',\n",
       "  'Project Intern\\n• Worked',\n",
       "  'MA Sep',\n",
       "  'Strava',\n",
       "  'TikTok'],\n",
       " 'Skills': ['outreach',\n",
       "  'retention',\n",
       "  'platform',\n",
       "  'estate',\n",
       "  'system',\n",
       "  'co',\n",
       "  'planning',\n",
       "  'phone',\n",
       "  'scouting',\n",
       "  'improvements',\n",
       "  'founders',\n",
       "  'knowledge',\n",
       "  'usability',\n",
       "  'email',\n",
       "  'design',\n",
       "  'training',\n",
       "  'PROJECTS',\n",
       "  'feedback',\n",
       "  'technology',\n",
       "  'study',\n",
       "  'profits',\n",
       "  'scikit',\n",
       "  'web',\n",
       "  'businesses',\n",
       "  'Founder',\n",
       "  'engagement',\n",
       "  'Activities',\n",
       "  'computer',\n",
       "  'models',\n",
       "  'course',\n",
       "  'development',\n",
       "  'drivers',\n",
       "  'acquisitions',\n",
       "  'trend',\n",
       "  'website',\n",
       "  'investments',\n",
       "  'calls',\n",
       "  'languages',\n",
       "  'user',\n",
       "  'recommendations',\n",
       "  'research',\n",
       "  'strategies',\n",
       "  'account',\n",
       "  'use',\n",
       "  'projects',\n",
       "  'efforts',\n",
       "  'service',\n",
       "  'skills',\n",
       "  'showcasing',\n",
       "  'metrics',\n",
       "  'app',\n",
       "  'others',\n",
       "  'portfolio',\n",
       "  'Oct',\n",
       "  'vision',\n",
       "  'websites',\n",
       "  'distractions',\n",
       "  'campaigns',\n",
       "  'machine',\n",
       "  'devices',\n",
       "  'learn',\n",
       "  'analysis',\n",
       "  'lives',\n",
       "  'count',\n",
       "  'dashboard',\n",
       "  'usage',\n",
       "  'frameworks',\n",
       "  'students',\n",
       "  'rates',\n",
       "  'likes',\n",
       "  'data',\n",
       "  'views',\n",
       "  'team',\n",
       "  'profit',\n",
       "  'accuracy',\n",
       "  'principles',\n",
       "  'follower',\n",
       "  'videos',\n",
       "  'mailings',\n",
       "  'accessibility',\n",
       "  'performance',\n",
       "  'analytics',\n",
       "  'area',\n",
       "  'services',\n",
       "  'work',\n",
       "  'algorithms',\n",
       "  'tips',\n",
       "  'followers',\n",
       "  'experiences',\n",
       "  'property',\n",
       "  'plans']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "file_path = \"example_resumes/NiamBashambuResumecopy.pdf\"\n",
    "parsed_data = parse_resume(file_path)\n",
    "parsed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously not very good, didn't get much meaning besides the name and email. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niam Bashambu\n",
      "niambashambu@icloud.com • 415-999-9281 • GitHub • LinkedIn • niambashambu.com\n",
      "EDUCATION\n",
      "Northeastern University | Boston, MA Aug 2023 - Present\n",
      "Khoury College of Computer Sciences Expected May 2027\n",
      "Bachelor of Sciences: Data Science and Business Administration GPA: 3.5/4.0\n",
      "Relevant course work: Advanced Programming with Data, Database Design, Foundations of Data Science,\n",
      "Algorithms and Data, Discrete Structures, Financial Accounting, Business Statistics\n",
      "Saint Louis University | Madrid, ES Aug 2023 - Dec 2023\n",
      "Semester Study Abroad\n",
      "Activities: Men’s Soccer\n",
      "TECHNICAL SKILLS\n",
      "Programming languages: Java, JavaScript, Python, SQL, HTML, CSS, Swift\n",
      "Applications: IntelliJ IDEA, VS-Code, PyCharm, Git, Xcode, Jupyter Notebook, Docker\n",
      "Frameworks and Libraries: React.js, TensorFlow, Node.js, NumPy, Pandas, Flask, Django, Keras, scikit-learn, Matplotlib\n",
      "PROFESSIONAL EXPERIENCE\n",
      "Belvidere Labs LLC | Boston, MA Sep 2024 - Oct 2024\n",
      "Founder\n",
      "• Created StudyPlanGPT, an app available on the Apple App Store to support students with personalized study planning.\n",
      "• Developed and delivered 3 user-friendly services designed to support students effectively.\n",
      "• Conducted user research and incorporated feedback to enhance service usability, resulting in increased usage.\n",
      "Bay Takes | Oakland, CA Aug 2021 - Dec 2023\n",
      "Content Producer\n",
      "• Collaborated with 4 others to create a TikTok account with 140k+ followers and 7M+ likes.\n",
      "• Used data analytics to grow follower count and perform trend analysis to increase engagement and viewer retention.\n",
      "• Featured in 50+ videos with 100,000+ views.\n",
      "Cooper Square Acquisitions | Camden, NJ Jul 2021 - Aug 2021\n",
      "Project Intern\n",
      "• Worked closely with co-founders on property scouting, acquisitions, and profit strategies in the Camden area.\n",
      "• Acquired valuable knowledge on maximizing profits from real estate investments.\n",
      "• Contributed to client outreach efforts through cold calls, email campaigns, and direct mailings.\n",
      "Develop Together | Remote Jun 2020 - Sep 2020\n",
      "Software Engineer Intern\n",
      "• Focused on building a platform that empowers small businesses to create and manage their own websites.\n",
      "• Collaborated with a team of 3 to successfully complete over 30 websites for small businesses.\n",
      "• Used React.js and other web development frameworks to complete these websites\n",
      "PROJECTS\n",
      "StudyPlanGPT | Node.js, Flask, Python, Swift Oct 2024 - Present\n",
      "• Created an iOS app focused on enhancing the academic lives of students available on the Apple App Store.\n",
      "• Utilizes OpenAI’s ChatGPT API to provide personalized study plans and tips.\n",
      "OptiRun | Node.js, Python, Swift Sep 2024 - Present\n",
      "• Utilized machine learning algorithms and user data from Strava to provide training recommendations.\n",
      "• Built a comprehensive user dashboard to track performance metrics and improvements.\n",
      "niambashambu.com | Javascript, HTML, CSS Jun 2023 - Present\n",
      "• Designed and developed a personal portfolio website showcasing projects, skills, and professional experiences\n",
      "• Implemented responsive design principles, ensuring accessibility across devices\n",
      "Distracted Driver Detection | Python, OpenCV, TensorFlow Jul 2020 - Aug 2020\n",
      "• Developed a system that detects distracted drivers using AI and computer vision technology.\n",
      "• Trained models to identify various distractions, including phone use, achieving high accuracy rates\n"
     ]
    }
   ],
   "source": [
    "#train data\n",
    "file_path = \"example_resumes/NiamBashambuResumecopy.pdf\"\n",
    "text = extract_text(file_path)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom spaCy NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Niam Bashambu', 'label': 'PERSON'},\n",
       " {'text': '415', 'label': 'CARDINAL'},\n",
       " {'text': 'Northeastern University', 'label': 'ORG'},\n",
       " {'text': 'Boston', 'label': 'GPE'},\n",
       " {'text': 'MA Aug', 'label': 'PERSON'},\n",
       " {'text': '2023', 'label': 'DATE'},\n",
       " {'text': 'Khoury College of Computer Sciences', 'label': 'ORG'},\n",
       " {'text': 'May 2027', 'label': 'DATE'},\n",
       " {'text': 'Bachelor of Sciences: Data Science and Business Administration GPA',\n",
       "  'label': 'ORG'},\n",
       " {'text': '3.5/4.0', 'label': 'CARDINAL'},\n",
       " {'text': 'Advanced Programming with Data', 'label': 'ORG'},\n",
       " {'text': 'Algorithms and Data, Discrete Structures', 'label': 'ORG'},\n",
       " {'text': 'Financial Accounting', 'label': 'ORG'},\n",
       " {'text': 'Business Statistics', 'label': 'ORG'},\n",
       " {'text': 'Saint Louis University', 'label': 'ORG'},\n",
       " {'text': 'Madrid', 'label': 'GPE'},\n",
       " {'text': '2023 - Dec 2023', 'label': 'DATE'},\n",
       " {'text': 'Java', 'label': 'PERSON'},\n",
       " {'text': 'JavaScript', 'label': 'PERSON'},\n",
       " {'text': 'SQL', 'label': 'ORG'},\n",
       " {'text': 'HTML', 'label': 'ORG'},\n",
       " {'text': 'CSS', 'label': 'ORG'},\n",
       " {'text': 'VS-Code', 'label': 'EVENT'},\n",
       " {'text': 'PyCharm', 'label': 'PERSON'},\n",
       " {'text': 'Git', 'label': 'PERSON'},\n",
       " {'text': 'Xcode', 'label': 'PERSON'},\n",
       " {'text': 'Jupyter Notebook', 'label': 'PERSON'},\n",
       " {'text': 'Node.js', 'label': 'GPE'},\n",
       " {'text': 'NumPy', 'label': 'GPE'},\n",
       " {'text': 'Pandas', 'label': 'PERSON'},\n",
       " {'text': 'Flask', 'label': 'GPE'},\n",
       " {'text': 'Django', 'label': 'GPE'},\n",
       " {'text': 'Keras', 'label': 'GPE'},\n",
       " {'text': 'Matplotlib', 'label': 'PERSON'},\n",
       " {'text': 'Belvidere Labs LLC', 'label': 'PERSON'},\n",
       " {'text': 'Boston', 'label': 'GPE'},\n",
       " {'text': 'MA Sep', 'label': 'ORG'},\n",
       " {'text': '• Developed', 'label': 'PERSON'},\n",
       " {'text': '3', 'label': 'CARDINAL'},\n",
       " {'text': '• Conducted', 'label': 'ORG'},\n",
       " {'text': 'Bay Takes', 'label': 'ORG'},\n",
       " {'text': 'Oakland', 'label': 'GPE'},\n",
       " {'text': 'CA Aug', 'label': 'PERSON'},\n",
       " {'text': '4', 'label': 'CARDINAL'},\n",
       " {'text': 'TikTok', 'label': 'ORG'},\n",
       " {'text': '140k+', 'label': 'CARDINAL'},\n",
       " {'text': '7M+', 'label': 'CARDINAL'},\n",
       " {'text': '• Featured', 'label': 'PERSON'},\n",
       " {'text': '50+', 'label': 'DATE'},\n",
       " {'text': '100,000', 'label': 'CARDINAL'},\n",
       " {'text': 'Cooper Square Acquisitions', 'label': 'FAC'},\n",
       " {'text': 'Camden', 'label': 'GPE'},\n",
       " {'text': 'NJ Jul', 'label': 'ORG'},\n",
       " {'text': '2021', 'label': 'DATE'},\n",
       " {'text': 'Project Intern\\n• Worked', 'label': 'ORG'},\n",
       " {'text': 'Camden', 'label': 'GPE'},\n",
       " {'text': '• Contributed', 'label': 'ORG'},\n",
       " {'text': 'Develop Together', 'label': 'PERSON'},\n",
       " {'text': 'Remote Jun', 'label': 'PERSON'},\n",
       " {'text': '• Collaborated', 'label': 'ORG'},\n",
       " {'text': '3', 'label': 'CARDINAL'},\n",
       " {'text': 'over 30', 'label': 'CARDINAL'},\n",
       " {'text': 'StudyPlanGPT', 'label': 'ORG'},\n",
       " {'text': 'Node.js', 'label': 'GPE'},\n",
       " {'text': 'Flask', 'label': 'GPE'},\n",
       " {'text': 'API', 'label': 'ORG'},\n",
       " {'text': 'OptiRun', 'label': 'ORG'},\n",
       " {'text': 'Strava', 'label': 'ORG'},\n",
       " {'text': 'Javascript', 'label': 'PERSON'},\n",
       " {'text': 'HTML', 'label': 'ORG'},\n",
       " {'text': 'CSS Jun', 'label': 'PERSON'},\n",
       " {'text': '2023 - Present\\n• Designed', 'label': 'DATE'},\n",
       " {'text': '• Implemented', 'label': 'ORG'},\n",
       " {'text': '2020', 'label': 'DATE'},\n",
       " {'text': 'AI', 'label': 'ORG'},\n",
       " {'text': '• Trained', 'label': 'ORG'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the pre-trained SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_with_spacy(text):\n",
    "    # Process the text to create a doc object\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract named entities\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append({\n",
    "            'text': ent.text,\n",
    "            'label': ent.label_\n",
    "        })\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Preprocess the text\n",
    "entities = preprocess_with_spacy(text)\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doesn't properly label everyting, could probably work on this to make it do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined Entities: ```json\n",
      "{\n",
      "  \"name\": \"Niam Bashambu\",\n",
      "  \"contact\": {\n",
      "    \"email\": \"niambashambu@icloud.com\",\n",
      "    \"phone\": \"415-999-9281\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"Northeastern University\",\n",
      "      \"location\": \"Boston, MA\",\n",
      "      \"start_date\": \"Aug 2023\",\n",
      "      \"expected_graduation\": \"May 2027\",\n",
      "      \"degree\": \"Bachelor of Sciences: Data Science and Business Administration\",\n",
      "      \"GPA\": \"3.5/4.0\"\n",
      "    },\n",
      "    {\n",
      "      \"institution\": \"Saint Louis University\",\n",
      "      \"location\": \"Madrid, ES\",\n",
      "      \"start_date\": \"Aug 2023\",\n",
      "      \"end_date\": \"Dec 2023\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": {\n",
      "    \"programming_languages\": [\"Java\", \"JavaScript\", \"Python\", \"SQL\", \"HTML\", \"CSS\", \"Swift\"],\n",
      "    \"applications\": [\"IntelliJ IDEA\", \"VS-Code\", \"PyCharm\", \"Git\", \"Xcode\", \"Jupyter Notebook\", \"Docker\"],\n",
      "    \"frameworks\": [\"React.js\", \"TensorFlow\", \"Node.js\", \"NumPy\", \"Pandas\", \"Flask\", \"Django\", \"Keras\", \"scikit-learn\", \"Matplotlib\"]\n",
      "  },\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"position\": \"Founder\",\n",
      "      \"company\": \"Belvidere Labs LLC\",\n",
      "      \"location\": \"Boston, MA\",\n",
      "      \"dates\": \"Sep 2024 - Oct 2024\"\n",
      "    },\n",
      "    {\n",
      "      \"position\": \"Content Producer\",\n",
      "      \"company\": \"Bay Takes\",\n",
      "      \"location\": \"Oakland, CA\",\n",
      "      \"dates\": \"Aug 2021 - Dec 2023\"\n",
      "    },\n",
      "    {\n",
      "      \"position\": \"Project Intern\",\n",
      "      \"company\": \"Cooper Square Acquisitions\",\n",
      "      \"location\": \"Camden, NJ\",\n",
      "      \"dates\": \"Jul 2021 - Aug 2021\"\n",
      "    },\n",
      "    {\n",
      "      \"position\": \"Software Engineer Intern\",\n",
      "      \"company\": \"Develop Together\",\n",
      "      \"location\": \"Remote\",\n",
      "      \"dates\": \"Jun 2020 - Sep 2020\"\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"StudyPlanGPT\",\n",
      "      \"technologies\": [\"\n"
     ]
    }
   ],
   "source": [
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Function to query GPT for contextual refinement\n",
    "def refine_entities_with_gpt(entities, text):\n",
    "    prompt = [{\"role\": \"user\", \"content\": f\"Parse the following resume text and provide only the important information, labeling each section appropriately (e.g., name, skills, education, experience, etc.). Ensure the response is concise, with minimal detail, and does not exceed the 500-character limit. The response should be in JSON format, containing only relevant information. There will also be entities provided that could help: {entities}. Here is the resume text: {text}\"}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Use the appropriate model\n",
    "        messages=prompt,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "\n",
    "    response = response.choices[0].message.content.strip()\n",
    "    return response\n",
    "\n",
    "# Refining the extracted entities\n",
    "refined_entities = refine_entities_with_gpt(entities, text)\n",
    "print(\"Refined Entities:\", refined_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used openai API, and it did a way better job to orgnaize everything in a json format as well. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
